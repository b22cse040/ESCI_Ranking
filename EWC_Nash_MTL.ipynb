{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now check the folder contents\n",
        "!ls -lh /content/drive/MyDrive/saved_crossencoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFXK_I_e4Sxr",
        "outputId": "3f3ad432-de27-470d-e88c-9052c866f71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "total 712M\n",
            "-rw------- 1 root root   23 Sep  1 16:04 added_tokens.json\n",
            "-rw------- 1 root root  783 Sep  1 16:04 config.json\n",
            "-rw------- 1 root root 702M Sep  1 16:06 pytorch_model.bin\n",
            "-rw------- 1 root root  286 Sep  1 16:04 special_tokens_map.json\n",
            "-rw------- 1 root root 2.4M Sep  1 16:04 spm.model\n",
            "-rw------- 1 root root 1.3K Sep  1 16:04 tokenizer_config.json\n",
            "-rw------- 1 root root 8.3M Sep  1 16:04 tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "import torch, os\n",
        "\n",
        "# Path on Google Drive\n",
        "model_path = \"/content/drive/MyDrive/saved_crossencoder\"\n",
        "\n",
        "class CrossEncoder(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        hidden_size = encoder.config.hidden_size\n",
        "        self.reg_head = nn.Linear(hidden_size, 1)\n",
        "        self.cls_head = nn.Linear(hidden_size, 4)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        reg_logits = self.reg_head(pooled_output).squeeze(-1)\n",
        "        cls_logits = self.cls_head(pooled_output)\n",
        "        return reg_logits, cls_logits\n",
        "\n",
        "# Load encoder from Drive\n",
        "encoder = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
        "\n",
        "# Load tokenizer from Drive\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "\n",
        "# Build model and load CrossEncoder head weights\n",
        "model = CrossEncoder(encoder)\n",
        "state_dict = torch.load(os.path.join(model_path, \"pytorch_model.bin\"), map_location=\"cpu\")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awE0I4-H0Fbu",
        "outputId": "9677d311-1fa0-4d20-cd8e-229c1c3c8cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2Model were not initialized from the model checkpoint at /content/drive/MyDrive/saved_crossencoder and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.LayerNorm.bias', 'encoder.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key_proj.bias', 'encoder.layer.0.attention.self.key_proj.weight', 'encoder.layer.0.attention.self.query_proj.bias', 'encoder.layer.0.attention.self.query_proj.weight', 'encoder.layer.0.attention.self.value_proj.bias', 'encoder.layer.0.attention.self.value_proj.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key_proj.bias', 'encoder.layer.1.attention.self.key_proj.weight', 'encoder.layer.1.attention.self.query_proj.bias', 'encoder.layer.1.attention.self.query_proj.weight', 'encoder.layer.1.attention.self.value_proj.bias', 'encoder.layer.1.attention.self.value_proj.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key_proj.bias', 'encoder.layer.10.attention.self.key_proj.weight', 'encoder.layer.10.attention.self.query_proj.bias', 'encoder.layer.10.attention.self.query_proj.weight', 'encoder.layer.10.attention.self.value_proj.bias', 'encoder.layer.10.attention.self.value_proj.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key_proj.bias', 'encoder.layer.11.attention.self.key_proj.weight', 'encoder.layer.11.attention.self.query_proj.bias', 'encoder.layer.11.attention.self.query_proj.weight', 'encoder.layer.11.attention.self.value_proj.bias', 'encoder.layer.11.attention.self.value_proj.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key_proj.bias', 'encoder.layer.2.attention.self.key_proj.weight', 'encoder.layer.2.attention.self.query_proj.bias', 'encoder.layer.2.attention.self.query_proj.weight', 'encoder.layer.2.attention.self.value_proj.bias', 'encoder.layer.2.attention.self.value_proj.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key_proj.bias', 'encoder.layer.3.attention.self.key_proj.weight', 'encoder.layer.3.attention.self.query_proj.bias', 'encoder.layer.3.attention.self.query_proj.weight', 'encoder.layer.3.attention.self.value_proj.bias', 'encoder.layer.3.attention.self.value_proj.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key_proj.bias', 'encoder.layer.4.attention.self.key_proj.weight', 'encoder.layer.4.attention.self.query_proj.bias', 'encoder.layer.4.attention.self.query_proj.weight', 'encoder.layer.4.attention.self.value_proj.bias', 'encoder.layer.4.attention.self.value_proj.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key_proj.bias', 'encoder.layer.5.attention.self.key_proj.weight', 'encoder.layer.5.attention.self.query_proj.bias', 'encoder.layer.5.attention.self.query_proj.weight', 'encoder.layer.5.attention.self.value_proj.bias', 'encoder.layer.5.attention.self.value_proj.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key_proj.bias', 'encoder.layer.6.attention.self.key_proj.weight', 'encoder.layer.6.attention.self.query_proj.bias', 'encoder.layer.6.attention.self.query_proj.weight', 'encoder.layer.6.attention.self.value_proj.bias', 'encoder.layer.6.attention.self.value_proj.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key_proj.bias', 'encoder.layer.7.attention.self.key_proj.weight', 'encoder.layer.7.attention.self.query_proj.bias', 'encoder.layer.7.attention.self.query_proj.weight', 'encoder.layer.7.attention.self.value_proj.bias', 'encoder.layer.7.attention.self.value_proj.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key_proj.bias', 'encoder.layer.8.attention.self.key_proj.weight', 'encoder.layer.8.attention.self.query_proj.bias', 'encoder.layer.8.attention.self.query_proj.weight', 'encoder.layer.8.attention.self.value_proj.bias', 'encoder.layer.8.attention.self.value_proj.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key_proj.bias', 'encoder.layer.9.attention.self.key_proj.weight', 'encoder.layer.9.attention.self.query_proj.bias', 'encoder.layer.9.attention.self.query_proj.weight', 'encoder.layer.9.attention.self.value_proj.bias', 'encoder.layer.9.attention.self.value_proj.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.rel_embeddings.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEncoder(\n",
              "  (encoder): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (reg_head): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (cls_head): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_A = pd.read_csv(\"filtered_test.csv\")"
      ],
      "metadata": {
        "id": "7D9k6Pie1y62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Creating dict for product info as prod_groups\n",
        "# and esci_label as label_groups\n",
        "prod_groups_train_A = defaultdict(list)\n",
        "prod_groups_test_A  = defaultdict(list)\n",
        "label_groups_train_A = defaultdict(list)\n",
        "label_groups_test_A  = defaultdict(list)\n",
        "\n",
        "def get_dicts(df, prod_groups, label_groups):\n",
        "  for _, row in df.iterrows():\n",
        "    query = row[\"query\"]\n",
        "    product = row[\"product_input\"]\n",
        "    relevance = float(row[\"esci_label\"])\n",
        "\n",
        "    prod_groups[query].append(product)\n",
        "    label_groups[query].append(relevance)\n",
        "\n",
        "# get_dicts(train_A, prod_groups_train, label_groups_train)\n",
        "get_dicts(test_A, prod_groups_test_A, label_groups_test_A)"
      ],
      "metadata": {
        "id": "pK3oxhlR1nKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ESCIDataset(Dataset):\n",
        "    def __init__(self, tokenizer, prod_groups, label_groups, max_len=128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.pairs = []\n",
        "        self.reg_labels = []\n",
        "        self.cls_labels = []\n",
        "\n",
        "        ## Labels are 0.0(I), 0.01(C), 0.1(S) and 1.0(E),\n",
        "        ## Models would prefer to promote with labels 1.0 and 0.1\n",
        "        ## over 0.01 and 0.0\n",
        "\n",
        "        score_to_index = {0.0: 0, 0.01: 1, 0.1: 2, 1.0: 3}\n",
        "\n",
        "        for query in prod_groups:\n",
        "            product_info = prod_groups[query]\n",
        "            labels = label_groups[query]\n",
        "\n",
        "            for idx, label in enumerate(labels):\n",
        "                self.pairs.append((query, product_info[idx]))\n",
        "                self.reg_labels.append(label)\n",
        "                self.cls_labels.append(score_to_index[label])\n",
        "\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        query, product = self.pairs[idx]\n",
        "        reg_label = self.reg_labels[idx]\n",
        "        cls_label = self.cls_labels[idx]\n",
        "\n",
        "        encoded = self.tokenizer(\n",
        "            query,\n",
        "            product,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        encoded = {k: v.squeeze(0) for k, v in encoded.items()}\n",
        "        encoded[\"reg_label\"] = torch.tensor(reg_label, dtype=torch.float)\n",
        "        encoded[\"cls_label\"] = torch.tensor(cls_label, dtype=torch.long)\n",
        "\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "3CAVzH8K19VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_dataset = ESCIDataset(tokenizer, prod_groups_test_A, label_groups_test_A, max_len=128)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "ds1DsPhC1-wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import ndcg_score\n",
        "# from collections import defaultdict\n",
        "# import torch.nn.functional as F\n",
        "# import torch\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# model.eval()\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# query_to_scores = defaultdict(list)\n",
        "# query_to_labels = defaultdict(list)\n",
        "\n",
        "# all_cls_preds = []\n",
        "# all_cls_trues = []\n",
        "\n",
        "# test_pairs = test_dataset.pairs\n",
        "# reg_labels = test_dataset.reg_labels\n",
        "# cls_labels = test_dataset.cls_labels\n",
        "\n",
        "# batch_size = 16\n",
        "# with torch.no_grad():\n",
        "#     for i in tqdm(range(0, len(test_pairs), batch_size), desc=\"Evaluating\"):\n",
        "#         batch_pairs = test_pairs[i:i+batch_size]\n",
        "#         batch_reg_labels = reg_labels[i:i+batch_size]\n",
        "#         batch_cls_labels = cls_labels[i:i+batch_size]\n",
        "\n",
        "#         queries = [q for q, _ in batch_pairs]\n",
        "#         products = [p for _, p in batch_pairs]\n",
        "\n",
        "#         encoded = tokenizer(\n",
        "#             queries,\n",
        "#             products,\n",
        "#             padding=\"max_length\",\n",
        "#             truncation=True,\n",
        "#             max_length=128,\n",
        "#             return_tensors=\"pt\"\n",
        "#         )\n",
        "\n",
        "#         input_ids = encoded[\"input_ids\"].to(device)\n",
        "#         attention_mask = encoded[\"attention_mask\"].to(device)\n",
        "\n",
        "#         reg_logits, cls_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "#         reg_scores = F.softplus(reg_logits).cpu().tolist()\n",
        "#         cls_preds = torch.argmax(F.softmax(cls_logits, dim=-1), dim=-1).cpu().tolist()\n",
        "#         cls_trues = batch_cls_labels\n",
        "\n",
        "#         for q, s, l in zip(queries, reg_scores, batch_reg_labels):\n",
        "#             query_to_scores[q].append(s)\n",
        "#             query_to_labels[q].append(l)\n",
        "\n",
        "#         all_cls_preds.extend(cls_preds)\n",
        "#         all_cls_trues.extend(cls_trues)\n",
        "\n",
        "# ndcg_total = 0\n",
        "# qualifiable_count = 0\n",
        "\n",
        "# for q in query_to_labels:\n",
        "#     labels = query_to_labels[q]\n",
        "#     scores = query_to_scores[q]\n",
        "#     if len(labels) > 1 and sum(labels) > 0:\n",
        "#         try:\n",
        "#             ndcg = ndcg_score([labels], [scores], k=10)\n",
        "#             ndcg_total += ndcg\n",
        "#             qualifiable_count += 1\n",
        "#         except ValueError:\n",
        "#             continue\n",
        "\n",
        "# avg_ndcg_10 = ndcg_total / qualifiable_count if qualifiable_count > 0 else 0\n",
        "\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# accuracy = accuracy_score(all_cls_trues, all_cls_preds)\n",
        "\n",
        "# print(f\"Average NDCG@10 (for {qualifiable_count} qualifiable queries): {avg_ndcg_10:.4f}\")\n",
        "# print(f\"Classification Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "I8a7AqrL2TgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retraining the Sub-Sample"
      ],
      "metadata": {
        "id": "gSyrA7k52apN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_B = pd.read_csv(\"filtered_train_B.csv\")\n",
        "test_B = pd.read_csv(\"filtered_test_B.csv\")\n",
        "\n",
        "train_B.shape, test_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbmxnuv01Lff",
        "outputId": "d9487c9e-c493-431c-8ae3-76cf9c992c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7227, 3), (1831, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Creating dict for product info as prod_groups\n",
        "# and esci_label as label_groups\n",
        "prod_groups_train_B = defaultdict(list)\n",
        "prod_groups_test_B  = defaultdict(list)\n",
        "label_groups_train_B = defaultdict(list)\n",
        "label_groups_test_B  = defaultdict(list)\n",
        "\n",
        "def get_dicts(df, prod_groups, label_groups):\n",
        "  for _, row in df.iterrows():\n",
        "    query = row[\"query\"]\n",
        "    product = row[\"product_input\"]\n",
        "    relevance = float(row[\"esci_label\"])\n",
        "\n",
        "    prod_groups[query].append(product)\n",
        "    label_groups[query].append(relevance)\n",
        "\n",
        "get_dicts(train_B, prod_groups_train_B, label_groups_train_B)\n",
        "get_dicts(test_B, prod_groups_test_B, label_groups_test_B)"
      ],
      "metadata": {
        "id": "v85tmBa94pSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def list_ce_loss(logits, labels):\n",
        "    true_dist = F.softmax(labels, dim=0)\n",
        "    log_pred_dist = F.log_softmax(logits, dim=0)\n",
        "    return -torch.sum(true_dist * log_pred_dist)\n",
        "\n",
        "def rcr_loss_function(logits, reg_labels, alpha=0.3):\n",
        "    softplus_logits = F.softplus(logits)\n",
        "\n",
        "    mse_loss = F.mse_loss(softplus_logits, reg_labels)\n",
        "    listwise_loss = list_ce_loss(softplus_logits, reg_labels)\n",
        "\n",
        "    # return (1 - alpha) * mse_loss + alpha * listwise_loss\n",
        "    return {\n",
        "        \"mse\" : mse_loss,\n",
        "        \"listwise\" : listwise_loss\n",
        "    }\n",
        "\n",
        "def multitask_loss(reg_logits, cls_logits, reg_labels, cls_labels, x=1/3, alpha=0.5):\n",
        "    \"\"\"\n",
        "    x: weight for classification vs regression\n",
        "    alpha: weight inside RCR loss\n",
        "    \"\"\"\n",
        "    rcr = rcr_loss_function(reg_logits, reg_labels, alpha)\n",
        "    ce = F.cross_entropy(cls_logits, cls_labels)\n",
        "    # return (1 - x) * rcr + x * ce\n",
        "    return {\n",
        "        \"mse\" : rcr[\"mse\"],\n",
        "        \"listwise\" : rcr[\"listwise\"],\n",
        "        \"ce\" : ce\n",
        "    }"
      ],
      "metadata": {
        "id": "h-FdlNaQ31Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_dataset = ESCIDataset(tokenizer, prod_groups_train_B, label_groups_train_B, max_len=128)\n",
        "test_dataset = ESCIDataset(tokenizer, prod_groups_test_B, label_groups_test_B, max_len=128)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "UyxVYMBr4zlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from copy import deepcopy\n",
        "\n",
        "def get_grads(loss, model):\n",
        "    \"\"\"\n",
        "    Returns a 1D tensor of gradients for all model parameters, filling zeros if any parameter is unused.\n",
        "    \"\"\"\n",
        "    param_list = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "    grads = torch.autograd.grad(\n",
        "        outputs=loss,\n",
        "        inputs=param_list,\n",
        "        retain_graph=True,\n",
        "        create_graph=False,\n",
        "        allow_unused=True\n",
        "    )\n",
        "\n",
        "    flat_grads = []\n",
        "    for p, g in zip(param_list, grads):\n",
        "        if g is None:\n",
        "            flat_grads.append(torch.zeros_like(p).view(-1))  # zero for unused params\n",
        "        else:\n",
        "            flat_grads.append(g.contiguous().view(-1))\n",
        "\n",
        "    return torch.cat(flat_grads)"
      ],
      "metadata": {
        "id": "pHelW6zn45k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def solve_nash_weights(task_grads, lr=8e-6, weight_decay=0.01, steps=20):\n",
        "  \"\"\"\n",
        "  task_grads: list of grad vectors for each task\n",
        "  \"\"\"\n",
        "\n",
        "  T = len(task_grads)\n",
        "  G = torch.stack(task_grads)\n",
        "\n",
        "  w = torch.ones(T, device = G.device, requires_grad=True)\n",
        "\n",
        "  optimizer = optim.AdamW([w], lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "  for _ in range(steps):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    agg_grad = torch.matmul(w, G)\n",
        "    grad_norm_sq = torch.sum(agg_grad ** 2)\n",
        "\n",
        "    loss = -torch.sum(torch.log(w + 1e-8) + 0.5 * grad_norm_sq)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      w.clamp_(min=1e-4)\n",
        "      w /= w.sum()\n",
        "\n",
        "  return w.detach()"
      ],
      "metadata": {
        "id": "_-tUfz-3474Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_old_params(model):\n",
        "    return {n: p.clone().detach() for n, p in model.named_parameters()}\n",
        "\n",
        "def compute_fisher(model, dataloader, num_samples=200, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    fisher = {n: torch.zeros_like(p, device=device) for n, p in model.named_parameters()}\n",
        "\n",
        "    data_iter = iter(dataloader)\n",
        "    for i in range(num_samples):\n",
        "        try:\n",
        "            batch = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(dataloader)\n",
        "            batch = next(data_iter)\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        cls_labels = batch[\"cls_label\"].to(device)\n",
        "\n",
        "        reg_logits, cls_logits = model(input_ids, attention_mask)\n",
        "\n",
        "        # Fisher usually uses CE loss on classification head\n",
        "        log_probs = torch.log_softmax(cls_logits, dim=-1)\n",
        "        class_ind = torch.multinomial(torch.exp(log_probs[0]), 1).item()\n",
        "        log_prob = log_probs[0, class_ind]\n",
        "\n",
        "        model.zero_grad()\n",
        "        log_prob.backward(retain_graph=True)\n",
        "\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.grad is not None:\n",
        "                fisher[n] += p.grad.detach() ** 2\n",
        "\n",
        "    for n in fisher:\n",
        "        fisher[n] /= num_samples\n",
        "\n",
        "    return fisher"
      ],
      "metadata": {
        "id": "G869AKWm5y-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ewc_loss(model, multitask_losses, fisher, old_params, lambda_ewc=1.0, weights=None):\n",
        "    # combine multitask losses\n",
        "    if weights is None:\n",
        "        combined = multitask_losses[\"mse\"] + multitask_losses[\"listwise\"] + multitask_losses[\"ce\"]\n",
        "    else:\n",
        "        combined = weights[0]*multitask_losses[\"mse\"] + weights[1]*multitask_losses[\"listwise\"] + weights[2]*multitask_losses[\"ce\"]\n",
        "\n",
        "    # EWC penalty\n",
        "    ewc_penalty = 0.0\n",
        "    for n, p in model.named_parameters():\n",
        "        if n in fisher:\n",
        "            ewc_penalty += (fisher[n] * (p - old_params[n])**2).sum()\n",
        "\n",
        "    return combined + (lambda_ewc / 2) * ewc_penalty"
      ],
      "metadata": {
        "id": "-5EtZ84W51LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# after finishing Task A\n",
        "old_params = save_old_params(model)\n",
        "fisher = compute_fisher(model, train_loader, num_samples=200, device=device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "lambda_ewc = 0.4  # tune this\n",
        "num_epochs = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_batches = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        reg_labels = batch[\"reg_label\"].to(device)\n",
        "        cls_labels = batch[\"cls_label\"].to(device)\n",
        "\n",
        "        reg_logits, cls_logits = model(input_ids, attention_mask)\n",
        "        multitask_losses = multitask_loss(reg_logits, cls_logits, reg_labels, cls_labels)\n",
        "\n",
        "        # Compute total EWC loss directly\n",
        "        loss = ewc_loss(model, multitask_losses, fisher, old_params, lambda_ewc)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_batches += 1\n",
        "\n",
        "        progress_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}], Avg Loss={total_loss/total_batches:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIGyuVW-55Sp",
        "outputId": "e5edad34-2d38-408f-e3f8-59a842551f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|███████████████████████████████████| 3614/3614 [12:36<00:00,  4.78it/s, Loss=0.0518]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Avg Loss=1.2814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import ndcg_score, accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, tokenizer, dataset, device, batch_size=16, max_len=128):\n",
        "    model.eval()\n",
        "\n",
        "    query_to_scores = defaultdict(list)\n",
        "    query_to_labels = defaultdict(list)\n",
        "\n",
        "    all_cls_preds = []\n",
        "    all_cls_trues = []\n",
        "\n",
        "    test_pairs = dataset.pairs\n",
        "    reg_labels = dataset.reg_labels\n",
        "    cls_labels = dataset.cls_labels\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(test_pairs), batch_size), desc=\"Evaluating\"):\n",
        "            batch_pairs = test_pairs[i:i+batch_size]\n",
        "            batch_reg_labels = reg_labels[i:i+batch_size]\n",
        "            batch_cls_labels = cls_labels[i:i+batch_size]\n",
        "\n",
        "            queries = [q for q, _ in batch_pairs]\n",
        "            products = [p for _, p in batch_pairs]\n",
        "\n",
        "            encoded = tokenizer(\n",
        "                queries,\n",
        "                products,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=max_len,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            input_ids = encoded[\"input_ids\"].to(device)\n",
        "            attention_mask = encoded[\"attention_mask\"].to(device)\n",
        "\n",
        "            reg_logits, cls_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Regression scores\n",
        "            reg_scores = F.softplus(reg_logits).cpu().tolist()\n",
        "            cls_preds = torch.argmax(F.softmax(cls_logits, dim=-1), dim=-1).cpu().tolist()\n",
        "\n",
        "            for q, s, l in zip(queries, reg_scores, batch_reg_labels):\n",
        "                query_to_scores[q].append(float(s))\n",
        "                query_to_labels[q].append(float(l))\n",
        "\n",
        "            all_cls_preds.extend(cls_preds)\n",
        "            all_cls_trues.extend(batch_cls_labels)\n",
        "\n",
        "    # ----- Ranking Metric -----\n",
        "    ndcg_total = 0\n",
        "    qualifiable_count = 0\n",
        "\n",
        "    for q in query_to_labels:\n",
        "        labels = query_to_labels[q]\n",
        "        scores = query_to_scores[q]\n",
        "        if len(labels) > 1 and sum(labels) > 0:\n",
        "            try:\n",
        "                ndcg = ndcg_score([labels], [scores], k=10)\n",
        "                ndcg_total += ndcg\n",
        "                qualifiable_count += 1\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    avg_ndcg_10 = ndcg_total / qualifiable_count if qualifiable_count > 0 else 0\n",
        "\n",
        "    # ----- Classification Metrics -----\n",
        "    accuracy = accuracy_score(all_cls_trues, all_cls_preds)\n",
        "\n",
        "    print(f\"Average NDCG@10 (for {qualifiable_count} queries): {avg_ndcg_10:.4f}\")\n",
        "    print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return avg_ndcg_10, accuracy\n",
        "\n",
        "\n",
        "avg_ndcg, acc, f1 = evaluate_model(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    test_dataset,\n",
        "    device,\n",
        "    batch_size=16,\n",
        "    max_len=128\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "pmyoIBd959HJ",
        "outputId": "67821f0f-8697-4311-d885-3f154729ee2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 115/115 [00:17<00:00,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average NDCG@10 (for 100 queries): 0.8963\n",
            "Classification Accuracy: 0.7231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-448651696.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m avg_ndcg, acc, f1 = evaluate_model(\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    }
  ]
}